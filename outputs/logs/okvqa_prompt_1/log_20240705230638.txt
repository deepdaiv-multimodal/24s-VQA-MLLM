{ TIMESTAMP         }-> 20240705230638
{ VERSION           }-> okvqa_prompt_1
{ CKPTS_DIR         }-> outputs/ckpts/okvqa_prompt_1
{ LOG_PATH          }-> outputs/logs/okvqa_prompt_1/log_20240705230638.txt
{ RESULT_DIR        }-> outputs/results/okvqa_prompt_1
{ RESULT_PATH       }-> outputs/results/okvqa_prompt_1/result_20240705230638.json
{ RESUME            }-> False
{ TASK              }-> ok
{ RUN_MODE          }-> prompt
{ DATA_TAG          }-> ok
{ DATA_MODE         }-> finetune
{ EVAL_NOW          }-> True
{ NUM_WORKERS       }-> 0
{ PIN_MEM           }-> True
{ cfg_file          }-> configs/prompt.yml
{ DEBUG             }-> False
{ SEED              }-> 99
{ EXAMPLES_PATH     }-> /root/workspace/BEiT3/24s-VQA-MLLM/outputs/results/beit3_base/examples.json
{ CANDIDATES_PATH   }-> /root/workspace/BEiT3/24s-VQA-MLLM/outputs/results/beit3_base/candidates.json
{ CAPTIONS_PATH     }-> assets/captions_okvqa.json
{ MODEL             }-> Salesforce/instructblip-flan-t5-xxl
{ TEMPERATURE       }-> 0.0
{ MAX_TOKENS        }-> 8
{ SLEEP_PER_INFER   }-> 10
{ PROMPT_HEAD       }-> Please choose the correct answer in the choices according to the context, the image tagging information, the question, the answer candidates. Each answer candidate is associated with a confidence score within a bracket. The true answer may not be included in the candidates. The image tagging information follows the format: object(confidence): [x_min, x_max, y_min, y_max].


{ LINE_PREFIX       }-> ===

{ N_EXAMPLES        }-> 20
{ K_CANDIDATES      }-> 10
{ T_INFER           }-> 5

